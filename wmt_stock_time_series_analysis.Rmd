---
title: "R Notebook"
output:
  html_document:
    df_print: paged
---

# Walmart stock Time Series Analysis

In this analysis, we look at the monthly stock price of Walmart over time. In this basic analysis, we examine the performance of the WMT stock over time, breaking down any seasonal trends, and building two different forecasting models to project stock performance after 2020 based on data from the previous decade.

Data was sourced from Yahoo Finance (link: https://finance.yahoo.com/quote/WMT/history?period1=83548800&period2=1656633600&interval=1mo&filter=history&frequency=1mo&includeAdjustedClose=true).

```{r}
library(forecast)
library(TTR)
library(dplyr)
library(Metrics)
library(remotes)
library(deepANN) # remotes::install_github("stschn/deepANN")

# read and format data
wmt <- read.csv('C:/Users/M33066/OneDrive - Noblis/Documents/Downloads/WMT.csv')
wmt <- subset(wmt, select = c(Date, Close))
head(wmt)
```


```{r}
# create subsets for forecasting analysis
test <- wmt
test <- test %>% filter(Date > '2019-12-01')

train <- wmt
train <- train %>% filter(Date <= '2019-12-01' & Date >= '2010-01-01')

wmt <- wmt %>% filter(Date >= '2010-01-01')

# convert dosage units to time series objects
train_ts <- ts(train$Close, frequency = 12, start = c(2010,1,1))
test_ts <- ts(test$Close, frequency = 12, start = c(2019,12,1))
wmt_ts <- ts(wmt$Close, frequency = 12, start = c(2010,1,1))

par(mfrow=c(1,1))
plot.ts(wmt_ts, main = 'WMT Stock Time-Series', ylab = 'Price')
```

```{r}
# trend analysis
wmt_de <- decompose(wmt_ts)
plot(wmt_de) 
wmt_de$seasonal
```

```{r}
# Simple Moving Average Analysis
# notice as n increases the predicted value trend smooths out
sma1 <- SMA(wmt_ts, n = 3) # using average of previous n values to determine prediction at current month
sma2 <- SMA(wmt_ts, n = 6)
sma3 <- SMA(wmt_ts, n = 12)
plot.ts(wmt_ts, main = 'Simple Moving Averages of WMT Time-Series')
lines(sma1, col = 2, lwd = 2) # n=3 Red
lines(sma2, col = 3, lwd = 2) # n=6 Green
lines(sma3, col = 4, lwd = 3) # n=12 BOLD Blue
grid(col = "lightgray")
legend(x = "bottomright",
       legend = c('WMT Actual','n=3','n=5','n=7'),
       col = c(1, 2, 3, 4),
       lwd = 2)
```

## Model

Using dosage unit data from 2010 through 2019 to build a predictive model for the 2020 to present data.

```{r}
# exponential smoothing for predicting the value at t+1 weights the more recent points heavily to make the prediction at t+1
# Holt-Winters 
  # alpha: coefficient for exponential smoothing
  # bet: coefficient for trend smoothing
  # gamma: coefficient for seasonal smoothing

wmt_for <- HoltWinters(train_ts)
wmt_for # contains all coefficients for level, trend, and seasonal smoothing

wmt_for2 <- HoltWinters(train_ts, beta = FALSE) # no trend smoothing
wmt_for3 <- HoltWinters(train_ts, gamma = FALSE) # no seasonal smoothing / less variability month to month without seasonal coefficients
wmt_for4 <- HoltWinters(train_ts, beta = FALSE, gamma = FALSE) # no trend or seasonal

par(mfrow=c(2,2)) # View of different parameters with Holt-Winters
plot(wmt_for, main = 'trend and seasonal smoothing')
plot(wmt_for2, main ='no trend smoothing')
plot(wmt_for3, main ='no seasonal smoothing')
plot(wmt_for4, main ='no trend or seasonal smoothing')
```

```{r}
# Holt-Winters forecast from 2010-2019 vs 2020-present Actual
HW_for <- forecast(wmt_for, h = 30)
plot(HW_for, fcol = 'blue', xlab = 'Time', ylab = 'Price')
grid(col = "lightgray")
lines(HW_for$fitted, lwd=2.5, col="darkgreen")
lines(test_ts, col="black")
legend(x = "bottomright",
       legend = c('WMT Actual','HW Model','HW Projection'),
       lty = 1,
       col = c(1, 'darkgreen', 'blue'),
       lwd = 2)  

# ARIMA model for auto regressive integrated moving average
  # auto regressive: predicts future values based on past values
  # integrated: data values are replaced by the difference between the data values and previous values
  # moving average: observation is dependent on average of lagged values
# parameters:
  # ARIMA(p, d, q)
  # p: number of lagged observations in the model
  # d: number of times raw observations are differences
  # q: size of the moving average window
# ARIMA combines auto regression with moving averages to account for trends, cycles, and seasonality

# ARIMA forecast
arima_model <- auto.arima(train_ts)
arima_for <- forecast(arima_model, h = 30)
plot(arima_for, fcol = 'blue', xlab = 'Time', ylab = 'Price')
grid(col = "lightgray")
lines(arima_for$fitted, lwd = 2.5, col="purple")
lines(wmt_ts, col="black")
legend(x = "bottomright",
       legend = c('WMT Actual', 'ARIMA Model','ARIMA Projection'),
       lty = 1,
       col = c(1, 'red', 'purple', 'blue'),
       lwd = 2)      

sarima_model <- arima(train_ts, order=c(0,1,0), seasonal = c(0,1,1))
sarima_for <- forecast(arima_model, h = 30)
plot(sarima_for, fcol = 'blue', xlab = 'Time', ylab = 'Price')
grid(col = "lightgray")
lines(sarima_for$fitted, lwd = 2.5, col="purple")
lines(wmt_ts, col="black")
legend(x = "bottomright",
       legend = c('WMT Actual', 'SARIMA Model','SARIMA Projection'),
       lty = 1,
       col = c(1, 'red', 'purple', 'blue'),
       lwd = 2)      
```

### Model Performance on 2020 to present data

Residual histograms: compare the distributions of residuals visually  

MAE: Mean Average Error averages all the differences from the model predictions to the actual values (average of the absolute value of the residuals)  
  -how much inaccuracy we can expect from the forecast on average
  -MAE does not reveal the proportional scale of the error, it can be difficult to distinguish between large and little errors  
  -might obscure issues related to low data volume  
  
MAPE: Mean Absolute Percentage Error averages the absolute percent differences between predicted values and actual values  
  -like MAE, MAPE understates the impact of big but rare errors caused by extreme values  
  -might obscure issues related to low data volume  

MSE: Mean Squared Error averages the squared difference between predicted values and actual values  
  -known as the metric that evaluates the quality of a forecasting model or predictor  
  -penalizes large errors or outliers more than minor errors due to the square term  
  -When dealing with low data volume, this statistic may ignore issues  

WAPE: Weighted Average Percentage error averages the percent differences between predicted values and actual values weighted by their realized values  
  -similar to MAPE, but instead of weighting by number of observations, the measure weights by realized value  

RSME: Root Squared Mean Error

```{r}
par(mfrow=c(2,1))

# residual comparison / fairly similar
hist(HW_for$residuals, xlim = range(-20,20), main = 'Actual and Predicted Value Differences Histogram - Holt-Winters', xlab = 'Difference')
grid(nx = 0, ny = NULL, col = "lightgray", lty = 1)
hist(HW_for$residuals, add = TRUE, xlim = range(-20,20), main = 'Actual and Predicted Value Differences Histogram - Holt-Winters', xlab = 'Difference')

hist(arima_for$residuals, xlim = range(-20,20), main = 'Actual and Predicted Value Differences Histogram - ARIMA', xlab = 'Difference')
grid(nx = 0, ny = NULL, col = "lightgray", lty = 1)
hist(arima_for$residuals, add = TRUE, xlim = range(-20,20), main = 'Actual and Predicted Value Differences Histogram - ARIMA', xlab = 'Difference')


# Assess performance of model on the test data
model_measures = data.frame(Model = rep(c('Holt-Winters','ARIMA'), 5), Measure = rep(c('MAE','MAPE','MSE','WAPE', 'RMSE'), each = 2),
                Value=round(
                  c(
                    mae(test_ts, HW_for$mean), # Mean average error
                    mae(test_ts, arima_for$mean),
                    mape(test_ts, HW_for$mean), # Mean average percentage error
                    mape(test_ts, arima_for$mean),
                    mse(test_ts, HW_for$mean), # Mean average error from predicted to actual
                    mse(test_ts, arima_for$mean),
                    wape(actuals = test_ts, preds = HW_for$mean),
                    wape(actuals = test_ts, preds = arima_for$mean),
                    rmse(actuals = test_ts, preds = HW_for$mean),
                    rmse(actuals = test_ts, preds = arima_for$mean)
                  ), 6
                )
              )
model_measures
```

#### Model Performance using historical data

```{r}
train_HW <- wmt
train_HW <- train_HW %>% filter(Date <= '2019-12-01' & Date >= '2011-01-01')
train_HW_ts <- ts(train_HW$Close, frequency = 12, start = c(2011,1,1))

model_measures = data.frame(Model = rep(c('Holt-Winters','ARIMA'), 5), Measure = rep(c('MAE','MAPE','MSE','WAPE', 'RMSE'), each = 2),
                Value=round(
                  c(
                    mae(train_HW_ts, HW_for$fitted), # fitted average error
                    mae(train_ts, arima_for$fitted),
                    mape(train_HW_ts, HW_for$fitted), # fitted average percentage error
                    mape(train_ts, arima_for$fitted),
                    mse(train_HW_ts, HW_for$fitted), # fitted average error from predicted to actual
                    mse(train_ts, arima_for$fitted),
                    wape(actuals = train_HW_ts, preds = HW_for$fitted),
                    wape(actuals = train_ts, preds = arima_for$fitted),
                    rmse(actuals = train_HW_ts, preds = HW_for$fitted),
                    rmse(actuals = train_ts, preds = arima_for$fitted)
                  ), 6
                )
              )
model_measures
```

Based on performance metrics, the ARIMA model proved to be a better forecasting model in all the data subsets. The performance metrics were closer to 0, indicating a less degree of error compared to its Holt-Winters counterpart.
